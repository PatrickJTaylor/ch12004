{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb82fd57-519f-4cd7-8ee1-e825ec12875f",
   "metadata": {},
   "source": [
    "# File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d81e1-99c4-41c8-acf2-b3c27ab74112",
   "metadata": {},
   "source": [
    "In all of the exercises you have completed thus far, any data that you need has been provided to you directly as Python objects e.g.\n",
    "\n",
    "```python\n",
    "concentration_data = [0.001, 0.002, 0.004, 0.006, 0.008, 0.010, 0.020]\n",
    "```\n",
    "\n",
    "This is not really representative of a typical data anlysis workflow. Most of the time, if you want to analyse some data, you will already have collected that data and stored it in some kind of **file**, perhaps a `csv` for example. It seems prudent therefore to learn how we can **read** files into Python and **write** files back out of Python: **file I/O** (input/output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1f14c-2b4f-4fdd-a462-b51d7e726496",
   "metadata": {},
   "source": [
    "## The general case: reading in files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2021e466-b1b3-43b8-a4b1-e38a22457ddf",
   "metadata": {},
   "source": [
    "The most general way to read data from a file in Python is to use the built-in `open` function. Let's look at a simple example: reading in a file that contains some simple text. We're going to look at [example.txt](), which looks like this:\n",
    "\n",
    "```none\n",
    "EXAMPLE TEXT FILE\n",
    "\n",
    "Here is some text.\n",
    "Here is some more text.\n",
    "\n",
    "Here is even more text.\n",
    "```\n",
    "\n",
    "Here's how we can read in this file in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c21b1d-4352-4245-bfb4-fbbc22ac5568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE TEXT FILE\n",
      "\n",
      "Here is some text.\n",
      "Here is some more text.\n",
      "\n",
      "Here is even more text.\n"
     ]
    }
   ],
   "source": [
    "with open('example.txt', 'r') as stream:\n",
    "    lines = stream.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee09ef8-a671-4023-aaff-ba7be3e78f51",
   "metadata": {},
   "source": [
    "To try this example yourself, download [example.txt](https://raw.githubusercontent.com/pythoninchemistry/ch12004/main/CH12004/lab_5/example.txt).\n",
    "\n",
    "Let's take this example in sections. First up, we have the `open` function:\n",
    "\n",
    "```python\n",
    "with open('example.txt', 'r') as stream:\n",
    "```\n",
    "\n",
    "Here we provide two arguments: the path to the file we want to open (`example.txt`) and what we would like to do with that file (`'r'` for **read**).\n",
    "\n",
    "As you will have already have noticed, we have also used a new keyword: `with`. Here we are doing something quite similar to `import` statements such as:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "We are effectively \"nicknaming\" the output of the `open` function and calling it `stream` instead. You could of course call it something else instead, here we use `stream` as shorthand for a **file stream**: a stream of data read from a file. \n",
    "\n",
    "We end the first line with a colon `:` much like function definitions and loops, after which we **indent** all of the code which needs to access `stream`. \n",
    "\n",
    "```python\n",
    "    lines = stream.readlines()\n",
    "```\n",
    "\n",
    "The next line actually manipulates the content of the file. The `open` function returns an object which contains all of the data associated with the file, but not necessarily in human-readable or immediately useful way. By calling the `readlines` method, we store a `list` containing each line of the file. The remaining code simply prints these lines for our inspection:\n",
    "\n",
    "```python\n",
    "for line in lines:\n",
    "    print(line, end='')\n",
    "```\n",
    "\n",
    "We have used the `end` keyword argument here just to prevent the `print` function from adding needless whitespace to the output (by default each line passed to `print` will be followed by a newline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ed8b8-86de-4a9a-b592-bfb93f1cee37",
   "metadata": {},
   "source": [
    "## Writing files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c07d6-861f-42fc-bdaf-cb02e8db75d8",
   "metadata": {},
   "source": [
    "Now that we've read in our simple text file, let's make some modifications to it and write it back out again.\n",
    "\n",
    "We now have the contents of the text file available to us in the form of a `list` of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4474803-402f-452d-98cb-40f70788589f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXAMPLE TEXT FILE\\n',\n",
       " '\\n',\n",
       " 'Here is some text.\\n',\n",
       " 'Here is some more text.\\n',\n",
       " '\\n',\n",
       " 'Here is even more text.\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471dd69-2899-4f35-8260-73494c592a3e",
   "metadata": {},
   "source": [
    "Note that each `\\n` is a **newline character** which will actually **become** a newline when passed to the `print` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64b2277-8978-4ea3-9d4d-d6e7055652fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1\n",
      "Line 2\n"
     ]
    }
   ],
   "source": [
    "print('Line 1\\nLine 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab5a14-ec05-4956-ba88-8e156da96869",
   "metadata": {},
   "source": [
    "Let's make some changes to `lines`, starting by removing the last two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77ae9f9-e13c-429e-a846-fc8268e8efa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXAMPLE TEXT FILE\\n',\n",
       " '\\n',\n",
       " 'Here is some text.\\n',\n",
       " 'Here is some more text.\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[:-2]\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915d29a-a6ce-419a-a44f-38b2ecf79abf",
   "metadata": {},
   "source": [
    "Now let's add a new line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5eae28-9769-41e1-b65a-a87c43fa86c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXAMPLE TEXT FILE\\n',\n",
       " '\\n',\n",
       " 'Here is some text.\\n',\n",
       " 'Here is some more text.\\n',\n",
       " 'This new text was added in Python!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.append('This new text was added in Python!')\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da0a17-0cb8-4503-adbf-cc1609ce34e4",
   "metadata": {},
   "source": [
    "And finally, to **write** our `lines` to a new **file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f7365c3-ffd8-4830-ab20-348aa2c36130",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modified_example.txt', 'w') as stream:\n",
    "    for line in lines:\n",
    "        stream.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53c949-636f-4b36-a3d9-94c22951d41c",
   "metadata": {},
   "source": [
    "If you followed along with this entire example, you should see that a new file `modified_example.txt` has now been created in the same directory as your Jupyter notebook - take a look.\n",
    "\n",
    "As you can see in the code above, writing a file in Python looks much like reading a file: we use the `open` function for both use cases. The difference is that here we specify that we want to **write** a file by passing `'w'` as the second argument, and we use the `write` method rather than the `readlines` method. The `write` method takes a single string as an argument, this is why we have used a `for` loop to write each individual line to a file. We could also have combined all of the lines into a single string beforehand and then passed this to the `write` method, either way will work just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196038ef-2f29-42ed-8124-ee819f4414e3",
   "metadata": {},
   "source": [
    "## Reading in scientific data with `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4dc640-c454-4c85-b4c9-b859e54db1a1",
   "metadata": {},
   "source": [
    "What we have just been through is the most general case: how to read in **any** file, regardless of what type of data is contained within. For our purposes, we are primarily intereseted in scientific data, numbers that have been collected during some series of experiments. There are many Python packages that can be used to read such data, here we're going to rely on one that we've already been introduced to: `numpy`.\n",
    "\n",
    "Time for another example file, this time some experimental data looking at the temperature dependence of the equilibrium constant for a reaction:\n",
    "\n",
    "```none\n",
    "# T / K | K\n",
    "100 2.38e38\n",
    "120 2.15e30\n",
    "140 3.86e24\n",
    "160 1.89e20\n",
    "180 8.42e16\n",
    "200 1.75e14\n",
    "220 1.12e12\n",
    "240 1.67e10\n",
    "260 4.73e08\n",
    "280 2.24e07\n",
    "300 1.59e06\n",
    "320 1.57e05\n",
    "340 2.03e04\n",
    "360 3.30e03\n",
    "380 6.50e02\n",
    "400 1.51e02\n",
    "420 4.01e01\n",
    "440 1.21e01\n",
    "460 4.02e00\n",
    "480 1.47e00\n",
    "500 5.82e-01\n",
    "```\n",
    "\n",
    "Follow this [link]() to download this file.\n",
    "\n",
    "This data is formatted as simple text in a table of sorts, with values on each line being separated by whitespace. Simple tabular data can be read from files like this using the `loadtxt` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea6fdee-fc5c-45b8-861c-5b5721f5f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+02 2.38e+38]\n",
      " [1.20e+02 2.15e+30]\n",
      " [1.40e+02 3.86e+24]\n",
      " [1.60e+02 1.89e+20]\n",
      " [1.80e+02 8.42e+16]\n",
      " [2.00e+02 1.75e+14]\n",
      " [2.20e+02 1.12e+12]\n",
      " [2.40e+02 1.67e+10]\n",
      " [2.60e+02 4.73e+08]\n",
      " [2.80e+02 2.24e+07]\n",
      " [3.00e+02 1.59e+06]\n",
      " [3.20e+02 1.57e+05]\n",
      " [3.40e+02 2.03e+04]\n",
      " [3.60e+02 3.30e+03]\n",
      " [3.80e+02 6.50e+02]\n",
      " [4.00e+02 1.51e+02]\n",
      " [4.20e+02 4.01e+01]\n",
      " [4.40e+02 1.21e+01]\n",
      " [4.60e+02 4.02e+00]\n",
      " [4.80e+02 1.47e+00]\n",
      " [5.00e+02 5.82e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt('thermodynamic_data.dat')\n",
    "\n",
    "print(data)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051dded-5548-40f6-b603-51f0cba2e44a",
   "metadata": {},
   "source": [
    "We end up with a `numpy` **array** containing all of the data in the file. We can tell just from counting square brackets that this array is **two-dimensional**, in other words it's an array of arrays: a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd0a4e7f-01e2-4dc5-9fb2-fa1cdcd9fc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00e+02, 2.38e+38])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d58634-873f-4ba8-bfe9-e0d6e74944ac",
   "metadata": {},
   "source": [
    "As you can see from the code above, the first row of `data` is `[0.001, 0.005]` which is indeed the first row of data in the original file. This makes sense, but in all liklihood what we actually want is all of the temperature values in one array, and all of the equilibrium constant data in another array. We can achieve this by **transposing** the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f0d2556-6790-46eb-8456-8cee01c39df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+02 1.20e+02 1.40e+02 1.60e+02 1.80e+02 2.00e+02 2.20e+02 2.40e+02\n",
      "  2.60e+02 2.80e+02 3.00e+02 3.20e+02 3.40e+02 3.60e+02 3.80e+02 4.00e+02\n",
      "  4.20e+02 4.40e+02 4.60e+02 4.80e+02 5.00e+02]\n",
      " [2.38e+38 2.15e+30 3.86e+24 1.89e+20 8.42e+16 1.75e+14 1.12e+12 1.67e+10\n",
      "  4.73e+08 2.24e+07 1.59e+06 1.57e+05 2.03e+04 3.30e+03 6.50e+02 1.51e+02\n",
      "  4.01e+01 1.21e+01 4.02e+00 1.47e+00 5.82e-01]]\n"
     ]
    }
   ],
   "source": [
    "transposed_data = data.T\n",
    "\n",
    "print(transposed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ca141-46a1-435d-ad6b-758185ee34a8",
   "metadata": {},
   "source": [
    "Now we have an array that contains all the same data as before, but the **rows** are now **columns** and vice versa. This allows us to very easily assign the temperature and equilibrium constant values to separate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b35a0366-db00-452b-aa3f-8af0d6a0ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 120. 140. 160. 180. 200. 220. 240. 260. 280. 300. 320. 340. 360.\n",
      " 380. 400. 420. 440. 460. 480. 500.]\n",
      "[2.38e+38 2.15e+30 3.86e+24 1.89e+20 8.42e+16 1.75e+14 1.12e+12 1.67e+10\n",
      " 4.73e+08 2.24e+07 1.59e+06 1.57e+05 2.03e+04 3.30e+03 6.50e+02 1.51e+02\n",
      " 4.01e+01 1.21e+01 4.02e+00 1.47e+00 5.82e-01]\n"
     ]
    }
   ],
   "source": [
    "temperature, K = transposed_data\n",
    "\n",
    "print(temperature)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82c4ea-a1d9-466e-a05f-be96712bd710",
   "metadata": {},
   "source": [
    "We could also achieve this by changing how we originally read in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc46050e-bc22-4ab3-900e-a4f0703990fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 120. 140. 160. 180. 200. 220. 240. 260. 280. 300. 320. 340. 360.\n",
      " 380. 400. 420. 440. 460. 480. 500.]\n",
      "[2.38e+38 2.15e+30 3.86e+24 1.89e+20 8.42e+16 1.75e+14 1.12e+12 1.67e+10\n",
      " 4.73e+08 2.24e+07 1.59e+06 1.57e+05 2.03e+04 3.30e+03 6.50e+02 1.51e+02\n",
      " 4.01e+01 1.21e+01 4.02e+00 1.47e+00 5.82e-01]\n"
     ]
    }
   ],
   "source": [
    "temperature, K = np.loadtxt('thermodynamic_data.dat', unpack=True)\n",
    "\n",
    "print(temperature)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bd4fd3-830b-4153-bd6e-339e32fd1fc3",
   "metadata": {},
   "source": [
    "Here we have added the `unpack` keyword argument, which automatically transposes the output array for us, we are then using **multiple assignment** to immediately split the data into separate variables.\n",
    "\n",
    "---\n",
    "\n",
    "For one final example, let's look at reading in a `csv` file:\n",
    "\n",
    "```none\n",
    "# T / K | K\n",
    "100, 2.38e38\n",
    "120, 2.15e30\n",
    "140, 3.86e24\n",
    "160, 1.89e20\n",
    "180, 8.42e16\n",
    "200, 1.75e14\n",
    "220, 1.12e12\n",
    "240, 1.67e10\n",
    "260, 4.73e08\n",
    "280, 2.24e07\n",
    "300, 1.59e06\n",
    "320, 1.57e05\n",
    "340, 2.03e04\n",
    "360, 3.30e03\n",
    "380, 6.50e02\n",
    "400, 1.51e02\n",
    "420, 4.01e01\n",
    "440, 1.21e01\n",
    "460, 4.02e00\n",
    "480, 1.47e00\n",
    "500, 5.82e-01\n",
    "```\n",
    "\n",
    "This example is actually the same data as the previous case, but now with **commas** separating the values rather than solely **whitespace**. This seemingly minor difference is actually quite important, as we can see if we try to read in this file in the same way as the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197f2953-4a97-4ee2-99fa-a8eff0516bbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '100,' to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m temperature, K \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthermodynamic_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(temperature)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(K)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/s2_python/lib/python3.12/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/s2_python/lib/python3.12/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string '100,' to float64 at row 0, column 1."
     ]
    }
   ],
   "source": [
    "temperature, K = np.loadtxt('thermodynamic_data.csv', unpack=True)\n",
    "\n",
    "print(temperature)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73385827-01da-4562-9e53-ef9798d86a04",
   "metadata": {},
   "source": [
    "The `ValueError` here gives us a good clue as to what's going wrong: `could not convert string '0.001,' to float64 at row 0, column 1.` This tells us that `numpy` is including the comma with each value, which we obviously do not want. This happens because the `loadtxt` function expects values to be separated by **whitespace** by default, not **commas**. We can change this with another **keyword argument**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea400f95-f9db-45c6-a5ea-f5e3951c7715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 120. 140. 160. 180. 200. 220. 240. 260. 280. 300. 320. 340. 360.\n",
      " 380. 400. 420. 440. 460. 480. 500.]\n",
      "[2.38e+38 2.15e+30 3.86e+24 1.89e+20 8.42e+16 1.75e+14 1.12e+12 1.67e+10\n",
      " 4.73e+08 2.24e+07 1.59e+06 1.57e+05 2.03e+04 3.30e+03 6.50e+02 1.51e+02\n",
      " 4.01e+01 1.21e+01 4.02e+00 1.47e+00 5.82e-01]\n"
     ]
    }
   ],
   "source": [
    "temperature, K = np.loadtxt('thermodynamic_data.csv', unpack=True, delimiter=',')\n",
    "\n",
    "print(temperature)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb096eb-6235-479e-9028-569791a64633",
   "metadata": {},
   "source": [
    "By setting the `delimiter` to a comma `,`, the `loadtxt` function is able to successfully parse the data and we end up with the same result as our previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28433413-7291-4bb2-92ee-a34c6e24cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
