{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb82fd57-519f-4cd7-8ee1-e825ec12875f",
   "metadata": {},
   "source": [
    "# File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d81e1-99c4-41c8-acf2-b3c27ab74112",
   "metadata": {},
   "source": [
    "In all of the exercises you have completed thus far, any data that you need has been provided to you directly as Python objects e.g.\n",
    "\n",
    "```python\n",
    "concentration_data = [0.001, 0.002, 0.004, 0.006, 0.008, 0.010, 0.020]\n",
    "```\n",
    "\n",
    "This is not really representative of a typical data anlysis workflow. Most of the time, if you want to analyse some data, you will already have collected that data and stored it in some kind of **file**, perhaps a `csv` for example. It seems prudent therefore to learn how we can **read** files into Python and **write** files back out of Python: **file I/O** (input/output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1f14c-2b4f-4fdd-a462-b51d7e726496",
   "metadata": {},
   "source": [
    "## The general case: reading in files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2021e466-b1b3-43b8-a4b1-e38a22457ddf",
   "metadata": {},
   "source": [
    "The most general way to read data from a file in Python is to use the built-in `open` function. Let's look at a simple example: reading in a file that contains some simple text. We're going to look at [example.txt](), which looks like this:\n",
    "\n",
    "```none\n",
    "EXAMPLE TEXT FILE\n",
    "\n",
    "Here is some text.\n",
    "Here is some more text.\n",
    "\n",
    "Here is even more text.\n",
    "```\n",
    "\n",
    "Here's how we can read in this file in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c21b1d-4352-4245-bfb4-fbbc22ac5568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE TEXT FILE\n",
      "\n",
      "Here is some text.\n",
      "Here is some more text.\n",
      "\n",
      "Here is even more text.\n"
     ]
    }
   ],
   "source": [
    "with open('example.txt', 'r') as stream:\n",
    "    lines = stream.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee09ef8-a671-4023-aaff-ba7be3e78f51",
   "metadata": {},
   "source": [
    "To try this example yourself ...\n",
    "\n",
    "Let's take this example in sections. First up, we have the `open` function:\n",
    "\n",
    "```python\n",
    "with open('example.txt', 'r') as stream:\n",
    "```\n",
    "\n",
    "Here we provide two arguments: the path to the file we want to open (`example.txt`) and what we would like to do with that file (`'r'` for **read**).\n",
    "\n",
    "As you will have already have noticed, we have also used a new keyword: `with`. Here we are doing something quite similar to `import` statements such as:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "We are effectively \"nicknaming\" the output of the `open` function and calling it `stream` instead. You could of course call it something else instead, here we use `stream` as shorthand for a **file stream**: a stream of data read from a file. \n",
    "\n",
    "We end the first line with a colon `:` much like function definitions and loops, after which we **indent** all of the code which needs to access `stream`. \n",
    "\n",
    "```python\n",
    "    lines = stream.readlines()\n",
    "```\n",
    "\n",
    "The next line actually manipulates the content of the file. The `open` function returns an object which contains all of the data associated with the file, but not necessarily in human-readable or immediately useful way. By calling the `readlines` method, we store a `list` containing each line of the file. The remaining code simply prints these lines for our inspection:\n",
    "\n",
    "```python\n",
    "for line in lines:\n",
    "    print(line, end='')\n",
    "```\n",
    "\n",
    "We have used the `end` keyword argument here just to prevent the `print` function from adding needless whitespace to the output (by default each line passed to `print` will be followed by a newline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ed8b8-86de-4a9a-b592-bfb93f1cee37",
   "metadata": {},
   "source": [
    "## Writing files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c07d6-861f-42fc-bdaf-cb02e8db75d8",
   "metadata": {},
   "source": [
    "Now that we've read in our simple text file, let's make some modifications to it and write it back out again.\n",
    "\n",
    "We now have the contents of the text file available to us in the form of a `list` of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4474803-402f-452d-98cb-40f70788589f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXAMPLE TEXT FILE\\n',\n",
       " '\\n',\n",
       " 'Here is some text.\\n',\n",
       " 'Here is some more text.\\n',\n",
       " '\\n',\n",
       " 'Here is even more text.\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471dd69-2899-4f35-8260-73494c592a3e",
   "metadata": {},
   "source": [
    "Note that each `\\n` is a **newline character** which will actually **become** a newline when passed to the `print` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64b2277-8978-4ea3-9d4d-d6e7055652fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1\n",
      "Line 2\n"
     ]
    }
   ],
   "source": [
    "print('Line 1\\nLine 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab5a14-ec05-4956-ba88-8e156da96869",
   "metadata": {},
   "source": [
    "Let's make some changes to `lines`, starting by removing the last two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77ae9f9-e13c-429e-a846-fc8268e8efa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXAMPLE TEXT FILE\\n',\n",
       " '\\n',\n",
       " 'Here is some text.\\n',\n",
       " 'Here is some more text.\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[:-2]\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915d29a-a6ce-419a-a44f-38b2ecf79abf",
   "metadata": {},
   "source": [
    "Now let's add a new line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5eae28-9769-41e1-b65a-a87c43fa86c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXAMPLE TEXT FILE\\n',\n",
       " '\\n',\n",
       " 'Here is some text.\\n',\n",
       " 'Here is some more text.\\n',\n",
       " 'This new text was added in Python!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.append('This new text was added in Python!')\n",
    "\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da0a17-0cb8-4503-adbf-cc1609ce34e4",
   "metadata": {},
   "source": [
    "And finally, to **write** our `lines` to a new **file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7365c3-ffd8-4830-ab20-348aa2c36130",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modified_example.txt', 'w') as stream:\n",
    "    for line in lines:\n",
    "        stream.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53c949-636f-4b36-a3d9-94c22951d41c",
   "metadata": {},
   "source": [
    "If you followed along with this entire example, you should see that a new file `modified_example.txt` has now been created in the same directory as your Jupyter notebook - take a look.\n",
    "\n",
    "As you can see in the code above, writing a file in Python looks much like reading a file: we use the `open` function for both use cases. The difference is that here we specify that we want to **write** a file by passing `'w'` as the second argument, and we use the `write` method rather than the `readlines` method. The `write` method takes a single string as an argument, this is why we have used a `for` loop to write each individual line to a file. We could also have combined all of the lines into a single string beforehand and then passed this to the `write` method, either way will work just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196038ef-2f29-42ed-8124-ee819f4414e3",
   "metadata": {},
   "source": [
    "## Reading in scientific data with `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4dc640-c454-4c85-b4c9-b859e54db1a1",
   "metadata": {},
   "source": [
    "What we have just been through is the most general case: how to read in **any** file, regardless of what type of data is contained within. For our purposes, we are primarily intereseted in scientific data, numbers that have been collected during some series of experiments. There are many Python packages that can be used to read such data, here we're going to rely on one that we've already been introduced to: `numpy`.\n",
    "\n",
    "Time for another example file, this time some experimental kinetic data looking at the concentration dependence of the rate of a reaction:\n",
    "\n",
    "```none\n",
    "# Concentration / M | Rate\n",
    "0.001 0.005\n",
    "0.050 0.270\n",
    "0.100 0.530\n",
    "0.150 0.790\n",
    "0.200 1.060\n",
    "0.250 1.320\n",
    "0.300 1.580\n",
    "0.350 1.850\n",
    "0.400 2.110\n",
    "0.450 2.370\n",
    "0.500 2.630\n",
    "0.550 2.900\n",
    "0.600 3.160\n",
    "0.650 3.420\n",
    "0.700 3.690\n",
    "0.750 3.950\n",
    "0.800 4.210\n",
    "0.850 4.470\n",
    "0.900 4.740\n",
    "0.950 4.740\n",
    "1.000 5.000\n",
    "```\n",
    "\n",
    "Follow this [link]() to download this file.\n",
    "\n",
    "This data is formatted as simple text in a table of sorts, with values on each line being separated by whitespace. Simple tabular data can be read from files like this using the `loadtxt` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea6fdee-fc5c-45b8-861c-5b5721f5f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e-03 5.00e-03]\n",
      " [5.00e-02 2.70e-01]\n",
      " [1.00e-01 5.30e-01]\n",
      " [1.50e-01 7.90e-01]\n",
      " [2.00e-01 1.06e+00]\n",
      " [2.50e-01 1.32e+00]\n",
      " [3.00e-01 1.58e+00]\n",
      " [3.50e-01 1.85e+00]\n",
      " [4.00e-01 2.11e+00]\n",
      " [4.50e-01 2.37e+00]\n",
      " [5.00e-01 2.63e+00]\n",
      " [5.50e-01 2.90e+00]\n",
      " [6.00e-01 3.16e+00]\n",
      " [6.50e-01 3.42e+00]\n",
      " [7.00e-01 3.69e+00]\n",
      " [7.50e-01 3.95e+00]\n",
      " [8.00e-01 4.21e+00]\n",
      " [8.50e-01 4.47e+00]\n",
      " [9.00e-01 4.74e+00]\n",
      " [9.50e-01 4.74e+00]\n",
      " [1.00e+00 5.00e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt('kinetic_data.dat')\n",
    "\n",
    "print(data)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051dded-5548-40f6-b603-51f0cba2e44a",
   "metadata": {},
   "source": [
    "We end up with a `numpy` **array** containing all of the data in the file. We can tell just from counting square brackets that this array is **two-dimensional**, in other words it's an array of arrays: a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0a4e7f-01e2-4dc5-9fb2-fa1cdcd9fc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.005])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d58634-873f-4ba8-bfe9-e0d6e74944ac",
   "metadata": {},
   "source": [
    "As you can see from the code above, the first row of `data` is `[0.001, 0.005]` which is indeed the first row of data in the original file. This makes sense, but in all liklihood what we actually want is all of the concentration values in one array, and all of the rate data in another array. We can achieve this by **transposing** the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0d2556-6790-46eb-8456-8cee01c39df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e-03 5.00e-02 1.00e-01 1.50e-01 2.00e-01 2.50e-01 3.00e-01 3.50e-01\n",
      "  4.00e-01 4.50e-01 5.00e-01 5.50e-01 6.00e-01 6.50e-01 7.00e-01 7.50e-01\n",
      "  8.00e-01 8.50e-01 9.00e-01 9.50e-01 1.00e+00]\n",
      " [5.00e-03 2.70e-01 5.30e-01 7.90e-01 1.06e+00 1.32e+00 1.58e+00 1.85e+00\n",
      "  2.11e+00 2.37e+00 2.63e+00 2.90e+00 3.16e+00 3.42e+00 3.69e+00 3.95e+00\n",
      "  4.21e+00 4.47e+00 4.74e+00 4.74e+00 5.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "transposed_data = data.T\n",
    "\n",
    "print(transposed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ca141-46a1-435d-ad6b-758185ee34a8",
   "metadata": {},
   "source": [
    "Now we have an array that contains all the same data as before, but the **rows** are now **columns** and vice versa. This allows us to very easily assign the concentration and rate values to separate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35a0366-db00-452b-aa3f-8af0d6a0ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001 0.05  0.1   0.15  0.2   0.25  0.3   0.35  0.4   0.45  0.5   0.55\n",
      " 0.6   0.65  0.7   0.75  0.8   0.85  0.9   0.95  1.   ]\n",
      "[0.005 0.27  0.53  0.79  1.06  1.32  1.58  1.85  2.11  2.37  2.63  2.9\n",
      " 3.16  3.42  3.69  3.95  4.21  4.47  4.74  4.74  5.   ]\n"
     ]
    }
   ],
   "source": [
    "concentration, rate = transposed_data\n",
    "\n",
    "print(concentration)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82c4ea-a1d9-466e-a05f-be96712bd710",
   "metadata": {},
   "source": [
    "We could also achieve this by changing how we originally read in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc46050e-bc22-4ab3-900e-a4f0703990fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001 0.05  0.1   0.15  0.2   0.25  0.3   0.35  0.4   0.45  0.5   0.55\n",
      " 0.6   0.65  0.7   0.75  0.8   0.85  0.9   0.95  1.   ]\n",
      "[0.005 0.27  0.53  0.79  1.06  1.32  1.58  1.85  2.11  2.37  2.63  2.9\n",
      " 3.16  3.42  3.69  3.95  4.21  4.47  4.74  4.74  5.   ]\n"
     ]
    }
   ],
   "source": [
    "concentration, rate = np.loadtxt('kinetic_data.dat', unpack=True)\n",
    "\n",
    "print(concentration)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bd4fd3-830b-4153-bd6e-339e32fd1fc3",
   "metadata": {},
   "source": [
    "Here we have added the `unpack` keyword argument, which automatically transposes the output array for us, we are then using **multiple assignment** to immediately split the data into separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f2953-4a97-4ee2-99fa-a8eff0516bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
